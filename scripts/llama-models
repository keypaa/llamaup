#!/usr/bin/env bash
# llama-models — HuggingFace GGUF model browser and downloader
#
# Optional TUI tool for browsing and downloading GGUF models from HuggingFace.
# Supports two modes:
#   - Premium: gum TUI + aria2c for fast downloads (opt-in)
#   - Minimal: bash-native select menu + curl (zero dependencies)
#
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly SCRIPT_DIR

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------
readonly MODELS_DIR="${HOME}/.local/share/llama-models"
readonly HF_API_URL="https://huggingface.co/api/models"
readonly VERSION="0.1.0"

# Mode will be set by detect_mode()
MODE=""

# ---------------------------------------------------------------------------
# Colour constants (only if stdout is a TTY)
# ---------------------------------------------------------------------------
if [[ -t 1 ]]; then
  RED='\033[0;31m'
  GREEN='\033[0;32m'
  YELLOW='\033[1;33m'
  CYAN='\033[0;36m'
  BLUE='\033[0;34m'
  MAGENTA='\033[0;35m'
  BOLD='\033[1m'
  DIM='\033[2m'
  RESET='\033[0m'
else
  RED=''
  GREEN=''
  YELLOW=''
  CYAN=''
  BLUE=''
  MAGENTA=''
  BOLD=''
  DIM=''
  RESET=''
fi

# ---------------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------------
error()   { echo -e "${RED}Error: $1${RESET}" >&2; exit 1; }
info()    { echo -e "${CYAN}→ $1${RESET}" >&2; }
success() { echo -e "${GREEN}✓ $1${RESET}" >&2; }
warn()    { echo -e "${YELLOW}⚠ $1${RESET}" >&2; }

# ---------------------------------------------------------------------------
# usage — print CLI help and exit 0
# ---------------------------------------------------------------------------
usage() {
  echo -e "${BOLD}llama-models${RESET} v${VERSION} — HuggingFace GGUF Model Browser"
  echo
  echo -e "${BOLD}USAGE${RESET}"
  echo "  llama-models [OPTIONS] [QUERY]"
  echo
  echo -e "${BOLD}DESCRIPTION${RESET}"
  echo "  Browse and download GGUF models from HuggingFace with a beautiful TUI."
  echo
  echo "  Two modes available:"
  echo -e "    ${GREEN}Premium${RESET}: Modern TUI with gum + ultra-fast aria2c downloads (opt-in)"
  echo -e "    ${BLUE}Minimal${RESET}: Bash-native menu + standard curl (zero dependencies)"
  echo
  echo -e "${BOLD}OPTIONS${RESET}"
  echo "  search <query>     Search for models matching query"
  echo "  list               List locally downloaded models"
  echo "  --mode <mode>      Force mode: 'premium' or 'minimal'"
  echo "  --install-deps     Install premium mode dependencies (gum + aria2c)"
  echo "  --version          Show version"
  echo "  -h, --help         Show this help"
  echo
  echo -e "${BOLD}EXAMPLES${RESET}"
  echo "  llama-models                    # Launch interactive browser"
  echo "  llama-models search qwen        # Search for \"qwen\" models"
  echo "  llama-models list               # Show downloaded models"
  echo "  llama-models --install-deps     # Install gum + aria2c"
  echo
  echo -e "${BOLD}STORAGE${RESET}"
  echo "  Models are downloaded to: ${MODELS_DIR}"
  echo
  echo -e "${BOLD}MORE INFO${RESET}"
  echo "  https://github.com/keypaa/llamaup"
  exit 0
}

# ---------------------------------------------------------------------------
# check_dependency — check if a command exists
# Args: $1 = command name
# Returns: 0 if exists, 1 if not
# ---------------------------------------------------------------------------
check_dependency() {
  command -v "$1" >/dev/null 2>&1
}

# ---------------------------------------------------------------------------
# detect_mode — auto-detect which mode to use
# Sets the global MODE variable to "premium" or "minimal"
# Args: $1 = action (optional: "list" won't trigger installation prompt)
# ---------------------------------------------------------------------------
detect_mode() {
  local action="${1:-}"
  local has_gum=false
  local has_aria2c=false
  
  check_dependency gum && has_gum=true
  check_dependency aria2c && has_aria2c=true
  
  # Premium mode requires both gum and aria2c
  if [[ "$has_gum" == "true" ]] && [[ "$has_aria2c" == "true" ]]; then
    MODE="premium"
    return 0
  fi
  
  # For list command, don't offer installation (it doesn't need premium deps)
  if [[ "$action" == "list" ]]; then
    MODE="minimal"
    return 0
  fi
  
  # Check if user wants to install dependencies (for interactive/search)
  if [[ "$has_gum" == "false" ]] || [[ "$has_aria2c" == "false" ]]; then
    offer_installation
  else
    MODE="minimal"
  fi
}

# ---------------------------------------------------------------------------
# offer_installation — prompt user to install premium dependencies
# ---------------------------------------------------------------------------
offer_installation() {
  echo
  echo -e "${BOLD}llama-models${RESET} — Enhanced Mode Available"
  echo
  echo -e "For the best experience, install optional dependencies:"
  echo -e "  ${GREEN}•${RESET} ${BOLD}gum${RESET}    — Modern TUI framework"
  echo -e "  ${GREEN}•${RESET} ${BOLD}aria2c${RESET} — Ultra-fast downloads (16x faster than curl)"
  echo
  echo -e "${DIM}Without these, you'll use basic mode (bash menu + curl)${RESET}"
  echo
  
  # Simple bash-native prompt
  read -p "Install enhanced mode dependencies? [Y/n] " -n 1 -r
  echo
  
  if [[ $REPLY =~ ^[Yy]$ ]] || [[ -z $REPLY ]]; then
    install_dependencies
  else
    info "Using minimal mode (bash + curl)"
    MODE="minimal"
  fi
}

# ---------------------------------------------------------------------------
# install_dependencies — install gum and aria2c
# ---------------------------------------------------------------------------
install_dependencies() {
  info "Installing dependencies..."
  
  local os_type
  os_type="$(uname -s)"
  
  case "$os_type" in
    Linux)
      install_linux_dependencies
      ;;
    Darwin)
      install_macos_dependencies
      ;;
    *)
      warn "Unsupported OS: $os_type"
      warn "Please install manually:"
      echo "  - gum: https://github.com/charmbracelet/gum"
      echo "  - aria2c: https://aria2.github.io/"
      MODE="minimal"
      return 1
      ;;
  esac
  
  # Verify installation
  if check_dependency gum && check_dependency aria2c; then
    success "Dependencies installed successfully"
    MODE="premium"
  else
    warn "Installation incomplete. Using minimal mode."
    MODE="minimal"
  fi
}

# ---------------------------------------------------------------------------
# install_linux_dependencies — install on Linux
# ---------------------------------------------------------------------------
install_linux_dependencies() {
  # Detect package manager
  if check_dependency apt; then
    info "Installing via apt..."
    sudo apt update && sudo apt install -y aria2
    install_gum_linux
  elif check_dependency yum; then
    info "Installing via yum..."
    sudo yum install -y aria2
    install_gum_linux
  elif check_dependency pacman; then
    info "Installing via pacman..."
    sudo pacman -S --noconfirm aria2
    install_gum_linux
  else
    warn "No supported package manager found"
    return 1
  fi
}

# ---------------------------------------------------------------------------
# install_gum_linux — install gum binary on Linux
# ---------------------------------------------------------------------------
install_gum_linux() {
  local arch
  arch="$(uname -m)"
  local gum_url
  
  case "$arch" in
    x86_64)
      gum_url="https://github.com/charmbracelet/gum/releases/latest/download/gum_Linux_x86_64.tar.gz"
      ;;
    aarch64|arm64)
      gum_url="https://github.com/charmbracelet/gum/releases/latest/download/gum_Linux_arm64.tar.gz"
      ;;
    *)
      warn "Unsupported architecture: $arch"
      return 1
      ;;
  esac
  
  info "Downloading gum..."
  local tmp_dir
  tmp_dir="$(mktemp -d)"
  
  curl -fsSL "$gum_url" -o "$tmp_dir/gum.tar.gz"
  tar -xzf "$tmp_dir/gum.tar.gz" -C "$tmp_dir"
  
  # Install to ~/.local/bin
  mkdir -p "$HOME/.local/bin"
  mv "$tmp_dir/gum" "$HOME/.local/bin/gum"
  chmod +x "$HOME/.local/bin/gum"
  
  rm -rf "$tmp_dir"
  
  # Add to PATH if not already there
  if [[ ":$PATH:" != *":$HOME/.local/bin:"* ]]; then
    warn "Add ~/.local/bin to your PATH:"
    echo '  export PATH="$HOME/.local/bin:$PATH"'
  fi
}

# ---------------------------------------------------------------------------
# install_macos_dependencies — install on macOS via Homebrew
# ---------------------------------------------------------------------------
install_macos_dependencies() {
  if ! check_dependency brew; then
    warn "Homebrew not found. Install from: https://brew.sh"
    return 1
  fi
  
  info "Installing via Homebrew..."
  brew install gum aria2
}

# ===========================================================================
# PHASE 2: HuggingFace API Integration
# ===========================================================================

# ---------------------------------------------------------------------------
# search_models — query HuggingFace API for GGUF models
# Args: $1 = search query (optional, searches all if empty)
#       $2 = limit (optional, default 50)
# Returns: JSON array of models (via stdout)
# Exit: 1 on API failure or invalid JSON
# ---------------------------------------------------------------------------
search_models() {
  local query="${1:-}"
  local limit="${2:-50}"
  local skip="${3:-0}"
  local api_url="${HF_API_URL}"
  
  # Build query parameters
  # CRITICAL: full=true returns siblings array with file metadata
  local params="limit=${limit}&sort=downloads&direction=-1&full=true"
  
  # Add skip/offset for pagination
  if [[ "$skip" -gt 0 ]]; then
    params="${params}&skip=${skip}"
  fi
  
  # Add search filter if provided
  if [[ -n "$query" ]]; then
    # URL-encode the query (basic: replace spaces with %20)
    local encoded_query
    encoded_query=$(echo "$query" | sed 's/ /%20/g')
    params="${params}&search=${encoded_query}"
  fi
  
  # Filter by gguf tag
  params="${params}&filter=gguf"
  
  info "Searching HuggingFace for GGUF models..."
  [[ -n "$query" ]] && info "Query: ${BOLD}${query}${RESET}"
  
  # Make API request with timeout
  local response
  if ! response=$(curl -fsSL --max-time 30 "${api_url}?${params}"); then
    error "Failed to query HuggingFace API"
  fi
  
  # Validate JSON response
  if ! echo "$response" | jq empty 2>/dev/null; then
    error "Invalid JSON response from HuggingFace API"
  fi
  
  echo "$response"
}

# ---------------------------------------------------------------------------
# filter_gguf_models — extract only GGUF models from API results
# Args: $1 = JSON array from search_models
# Returns: Filtered JSON array with only GGUF models (via stdout)
# Note: Filters models that have .gguf files in siblings array
# ---------------------------------------------------------------------------
filter_gguf_models() {
  local json="$1"
  
  # Filter models that have .gguf files
  # Look for either:
  #   - 'gguf' in tags array
  #   - siblings array contains files ending with .gguf
  echo "$json" | jq '[.[] | select(
    (.tags // [] | any(. == "gguf")) or
    (.siblings // [] | any(.rfilename | endswith(".gguf")))
  )]'
}

# ---------------------------------------------------------------------------
# parse_model_metadata — extract metadata from a single model
# Args: $1 = model JSON object
# Returns: pipe-separated string: id|downloads|size|quant_count
# Example: "TheBloke/Llama-2-7B-GGUF|125000|7.2GiB|8"
# Note: Calculates size and count from siblings array (available with full=true)
# ---------------------------------------------------------------------------
parse_model_metadata() {
  local model_json="$1"
  
  local id downloads total_size quant_count
  
  # Extract basic info
  id=$(echo "$model_json" | jq -r '.id // .modelId // "unknown"')
  downloads=$(echo "$model_json" | jq -r '.downloads // 0')
  
  # Calculate total GGUF size and count from siblings
  quant_count=$(echo "$model_json" | jq -r '
    [.siblings // [] | .[] | select(.rfilename | endswith(".gguf"))] | length
  ')
  
  total_size=$(echo "$model_json" | jq -r '
    [.siblings // [] | .[] | select(.rfilename | endswith(".gguf")) | .size // 0] | add // 0
  ')
  
  # Format size (bytes to human-readable)
  local size_human
  if [[ "$total_size" -eq 0 ]]; then
    size_human="N/A"
  elif command -v numfmt >/dev/null 2>&1; then
    size_human=$(echo "$total_size" | numfmt --to=iec-i --suffix=B 2>/dev/null || echo "${total_size}B")
  else
    # Fallback: simple GiB conversion using awk
    size_human=$(awk "BEGIN {printf \"%.1fGiB\", $total_size/1024/1024/1024}")
  fi
  
  # Format downloads with thousands separator
  local downloads_human
  if command -v numfmt >/dev/null 2>&1; then
    downloads_human=$(echo "$downloads" | numfmt --grouping 2>/dev/null || echo "$downloads")
  else
    downloads_human="$downloads"
  fi
  
  # Output: id|downloads|size|quant_count
  echo "${id}|${downloads_human}|${size_human}|${quant_count}"
}

# ---------------------------------------------------------------------------
# list_gguf_files — list all GGUF files for a specific model
# Args: $1 = model JSON object
# Returns: JSON array of GGUF files with name, size, quant type
# Note: Extracts quant from filename using comprehensive regex patterns
# ---------------------------------------------------------------------------
list_gguf_files() {
  local model_json="$1"
  
  # Extract GGUF files with metadata
  # Quant detection regex (from filename):
  #   - Full precision: bf16, f16, f32
  #   - K-quants: Q8_0, Q6_K, Q5_K_M, Q4_K_S, etc.
  #   - Legacy: Q5_1, Q4_0, etc.
  #   - IQuant: IQ4_XS, IQ3_XXS, etc.
  echo "$model_json" | jq -r '
    .siblings // [] | 
    map(select(.rfilename | endswith(".gguf"))) |
    map({
      filename: .rfilename,
      size: .size,
      quant: (
        .rfilename | ascii_downcase |
        if test("bf16") then "BF16"
        elif test("f32") then "F32"
        elif test("f16") then "F16"
        elif test("q8_0") then "Q8_0"
        elif test("q6_k_l") then "Q6_K_L"
        elif test("q6_k") then "Q6_K"
        elif test("q5_k_m") then "Q5_K_M"
        elif test("q5_k_s") then "Q5_K_S"
        elif test("q5_1") then "Q5_1"
        elif test("q5_0") then "Q5_0"
        elif test("q4_k_m") then "Q4_K_M"
        elif test("q4_k_s") then "Q4_K_S"
        elif test("q4_1") then "Q4_1"
        elif test("q4_0") then "Q4_0"
        elif test("q3_k_l") then "Q3_K_L"
        elif test("q3_k_m") then "Q3_K_M"
        elif test("q3_k_s") then "Q3_K_S"
        elif test("q2_k") then "Q2_K"
        elif test("iq4_xs") then "IQ4_XS"
        elif test("iq4_nl") then "IQ4_NL"
        elif test("iq3_xxs") then "IQ3_XXS"
        elif test("iq3_xs") then "IQ3_XS"
        elif test("iq2_xxs") then "IQ2_XXS"
        elif test("iq2_xs") then "IQ2_XS"
        elif test("iq1_s") then "IQ1_S"
        elif test("mxfp4") then "MXFP4"
        else "UNKNOWN"
        end
      )
    })
  '
}

# ===========================================================================
# END PHASE 2
# ===========================================================================

# ===========================================================================
# PHASE 3: Minimal Mode Implementation
# ===========================================================================

# ---------------------------------------------------------------------------
# download_gguf_file — download a GGUF file from HuggingFace with progress
# Args: $1 = model_id (e.g. "bartowski/Llama-3.1-8B-GGUF")
#       $2 = filename (e.g. "Llama-3.1-8B-Q4_K_M.gguf")
#       $3 = dest_dir (directory to save to)
# Returns: 0 on success, 1 on failure
# Note: Uses curl with progress bar, similar to pull.sh download_file()
# ---------------------------------------------------------------------------
download_gguf_file() {
  local model_id="$1"
  local filename="$2"
  local dest_dir="$3"
  
  # HuggingFace direct download URL pattern
  local url="https://huggingface.co/${model_id}/resolve/main/${filename}"
  local dest_path="${dest_dir}/${filename}"
  
  # Create destination directory
  mkdir -p "$dest_dir"
  
  echo
  info "Downloading: ${BOLD}${filename}${RESET}"
  info "From: ${model_id}"
  echo
  
  # Download with curl and custom progress bar
  # Strategy: Start curl in background, monitor file size in real-time
  local bar_width=30
  
  # Start download in background, silently
  curl -L -f -s -o "$dest_path" "$url" &
  local curl_pid=$!
  
  # Monitor progress while curl is running
  local last_size=0
  local total_size=0
  
  # Try to get total size from Content-Length header
  total_size=$(curl -sI -L "$url" | grep -i content-length | tail -1 | awk '{print $2}' | tr -d '\r')
  
  while kill -0 "$curl_pid" 2>/dev/null; do
    if [[ -f "$dest_path" ]]; then
      local current_size
      current_size=$(stat -f%z "$dest_path" 2>/dev/null || stat -c%s "$dest_path" 2>/dev/null || echo "0")
      
      if [[ "$current_size" != "$last_size" ]]; then
        last_size="$current_size"
        
        # Calculate percentage
        local percent=0
        if [[ "$total_size" -gt 0 ]]; then
          percent=$((current_size * 100 / total_size))
        fi
        
        # Build progress bar
        local filled=$((percent * bar_width / 100))
        local empty=$((bar_width - filled))
        
        local bar=""
        for ((i=0; i<filled; i++)); do bar+="█"; done
        for ((i=0; i<empty; i++)); do bar+="░"; done
        
        # Format sizes
        local downloaded_str
        if [[ "$current_size" -ge 1073741824 ]]; then
          downloaded_str="$(awk "BEGIN {printf \"%.1fG\", $current_size/1073741824}")"
        elif [[ "$current_size" -ge 1048576 ]]; then
          downloaded_str="$(awk "BEGIN {printf \"%.0fM\", $current_size/1048576}")"
        else
          downloaded_str="$(awk "BEGIN {printf \"%.0fK\", $current_size/1024}")"
        fi
        
        local total_str=""
        if [[ "$total_size" -gt 0 ]]; then
          if [[ "$total_size" -ge 1073741824 ]]; then
            total_str="$(awk "BEGIN {printf \"%.1fG\", $total_size/1073741824}")"
          elif [[ "$total_size" -ge 1048576 ]]; then
            total_str="$(awk "BEGIN {printf \"%.0fM\", $total_size/1048576}")"
          else
            total_str="$(awk "BEGIN {printf \"%.0fK\", $total_size/1024}")"
          fi
        fi
        
        # Display progress
        if [[ -n "$total_str" ]]; then
          printf "\r${GREEN}%3d%%${RESET}|${CYAN}%s${RESET}| ${BOLD}%s${RESET}/${BOLD}%s${RESET}  " \
            "$percent" "$bar" "$downloaded_str" "$total_str"
        else
          printf "\r${CYAN}Downloading...${RESET} ${BOLD}%s${RESET}  " "$downloaded_str"
        fi
      fi
    fi
    sleep 0.5
  done
  
  # Wait for curl to finish and get exit code
  wait "$curl_pid"
  
  local exit_code=$?
  
  if [[ $exit_code -eq 0 ]] && [[ -f "$dest_path" ]] && [[ -s "$dest_path" ]]; then
    # Show 100% completion
    local bar=""
    for ((i=0; i<bar_width; i++)); do bar+="█"; done
    
    if [[ -z "$total_size" ]]; then
      local bytes
      bytes=$(stat -f%z "$dest_path" 2>/dev/null || stat -c%s "$dest_path" 2>/dev/null || echo "0")
      if [[ "$bytes" -ge 1073741824 ]]; then
        total_size="$(awk "BEGIN {printf \"%.1fG\", $bytes/1073741824}")"
      elif [[ "$bytes" -ge 1048576 ]]; then
        total_size="$(awk "BEGIN {printf \"%.0fM\", $bytes/1048576}")"
      else
        total_size="$(awk "BEGIN {printf \"%.0fK\", $bytes/1024}")"
      fi
    fi
    
    printf "\r${GREEN}%3d%%${RESET}|${CYAN}%s${RESET}| ${BOLD}%s${RESET}/${BOLD}%s${RESET}  \n" \
      "100" "$bar" "$total_size" "$total_size"
    
    echo
    success "Downloaded to: ${dest_path}"
    
    # Save metadata
    save_download_metadata "$dest_dir" "$model_id" "$filename" "$url"
    
    return 0
  else
    echo
    rm -f "$dest_path"
    error "Download failed from: ${url}"
  fi
}

# ---------------------------------------------------------------------------
# download_aria2c_file — download using aria2c for faster multi-connection
# Args: $1 = model_id (e.g. "bartowski/Llama-3.1-8B-GGUF")
#       $2 = filename (e.g. "Llama-3.1-8B-Q4_K_M.gguf")
#       $3 = dest_dir (directory to save to)
# Returns: 0 on success, 1 on failure
# Note: Uses aria2c with 16 connections for faster downloads
# ---------------------------------------------------------------------------
download_aria2c_file() {
  local model_id="$1"
  local filename="$2"
  local dest_dir="$3"
  
  # HuggingFace direct download URL pattern
  local url="https://huggingface.co/${model_id}/resolve/main/${filename}"
  local dest_path="${dest_dir}/${filename}"
  
  # Create destination directory
  mkdir -p "$dest_dir"
  
  echo
  info "Downloading: ${BOLD}${filename}${RESET}"
  info "From: ${model_id}"
  info "Using aria2c (16 connections)"
  echo
  
  # Download with aria2c
  # Options:
  #   -x16: Use 16 connections per server
  #   -s16: Split into 16 segments
  #   -j1: Download 1 file at a time
  #   --file-allocation=none: Don't pre-allocate disk space
  #   --console-log-level=warn: Reduce verbosity
  #   --summary-interval=1: Update progress every second
  #   -d: Download directory
  #   -o: Output filename
  if aria2c \
    -x16 \
    -s16 \
    -j1 \
    --file-allocation=none \
    --console-log-level=warn \
    --summary-interval=1 \
    -d "$dest_dir" \
    -o "$filename" \
    "$url"; then
    
    echo
    success "Downloaded to: ${dest_path}"
    
    # Save metadata
    save_download_metadata "$dest_dir" "$model_id" "$filename" "$url"
    
    return 0
  else
    echo
    rm -f "$dest_path"
    error "Download failed from: ${url}"
  fi
}

# ---------------------------------------------------------------------------
# save_download_metadata — save metadata JSON for a downloaded model
# Args: $1 = dest_dir (model directory)
#       $2 = model_id (HuggingFace model ID)
#       $3 = filename (GGUF filename)
#       $4 = source_url (download URL)
# Creates: {dest_dir}/metadata.json
# ---------------------------------------------------------------------------
save_download_metadata() {
  local dest_dir="$1"
  local model_id="$2"
  local filename="$3"
  local source_url="$4"
  
  local metadata_file="${dest_dir}/metadata.json"
  local file_path="${dest_dir}/${filename}"
  
  # Get file size
  local file_size=0
  local file_size_human="N/A"
  if [[ -f "$file_path" ]]; then
    file_size=$(stat -f%z "$file_path" 2>/dev/null || stat -c%s "$file_path" 2>/dev/null || echo "0")
    file_size_human=$(format_size "$file_size")
  fi
  
  # Extract quantization from filename (case-insensitive)
  local quant="unknown"
  local filename_upper="${filename^^}"  # Convert to uppercase for matching
  if [[ "$filename_upper" =~ (Q[0-9]_[0-9K_ML]+|F16|BF16|F32|IQ[0-9]_[A-Z]+|MXFP[0-9]) ]]; then
    quant="${BASH_REMATCH[1]}"
  fi
  
  # Get quality label for quantization
  local quant_label="Other"
  if [[ "$quant" != "unknown" ]]; then
    local label_result
    label_result=$(get_quant_label "$quant")
    quant_label="${label_result%%|*}"
  fi
  
  # Get current timestamp (ISO 8601 format)
  local download_date
  download_date=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
  
  # Build metadata JSON
  # If metadata file exists, append to downloads array; otherwise create new
  if [[ -f "$metadata_file" ]]; then
    # Append to existing downloads (avoid duplicates)
    local temp_file="${metadata_file}.tmp"
    jq --arg date "$download_date" \
       --arg url "$source_url" \
       --arg file "$filename" \
       --argjson size "$file_size" \
       --arg size_human "$file_size_human" \
       --arg quant "$quant" \
       --arg label "$quant_label" \
       '.downloads |= (map(select(.filename != $file)) + [{
         downloaded_at: $date,
         filename: $file,
         source_url: $url,
         file_size: $size,
         file_size_human: $size_human,
         quantization: $quant,
         quality_label: $label
       }])' "$metadata_file" > "$temp_file"
    mv "$temp_file" "$metadata_file"
  else
    # Create new metadata file
    cat > "$metadata_file" <<EOF
{
  "model_id": "${model_id}",
  "storage_path": "${dest_dir}",
  "downloads": [
    {
      "downloaded_at": "${download_date}",
      "filename": "${filename}",
      "source_url": "${source_url}",
      "file_size": ${file_size},
      "file_size_human": "${file_size_human}",
      "quantization": "${quant}",
      "quality_label": "${quant_label}"
    }
  ]
}
EOF
  fi
  
  info "Metadata saved: ${metadata_file}"
}

# ---------------------------------------------------------------------------
# format_size — convert bytes to human-readable size
# Args: $1 = size in bytes
# Returns: formatted string like "4.2GiB" or "512MiB"
# ---------------------------------------------------------------------------
format_size() {
  local bytes="$1"
  
  # Handle null, empty, or non-numeric values
  if [[ -z "$bytes" ]] || [[ "$bytes" == "null" ]] || ! [[ "$bytes" =~ ^[0-9]+$ ]]; then
    echo "N/A"
    return 0
  fi
  
  if [[ "$bytes" -eq 0 ]]; then
    echo "N/A"
  elif command -v numfmt >/dev/null 2>&1; then
    numfmt --to=iec-i --suffix=B "$bytes" 2>/dev/null || echo "${bytes}B"
  else
    # Fallback: simple conversion using awk
    if [[ "$bytes" -ge 1073741824 ]]; then
      awk "BEGIN {printf \"%.1fGiB\", $bytes/1073741824}"
    elif [[ "$bytes" -ge 1048576 ]]; then
      awk "BEGIN {printf \"%.0fMiB\", $bytes/1048576}"
    else
      awk "BEGIN {printf \"%.0fKiB\", $bytes/1024}"
    fi
  fi
}

# ---------------------------------------------------------------------------
# get_quant_label — classify quantization quality
# Args: $1 = quantization string (e.g. "Q4_K_M", "F16")
# Returns: label|color (e.g. "Lossless|GREEN" or "Lossy|RED")
# Note: Smaller models suffer more from quantization. On models < 7B, prefer Q6_K minimum.
# ---------------------------------------------------------------------------
get_quant_label() {
  local quant="$1"
  
  # Lossless / Full Precision
  # No loss, identical to original weights. Too large for most local machines.
  case "$quant" in
    F32|F16|BF16)
      echo "Lossless|${GREEN}"
      return 0
      ;;
  esac
  
  # Near-Lossless (imperceptible difference)
  # Quality almost identical to F16, loss < 0.1%. Sweet spot if you have the VRAM.
  case "$quant" in
    Q8_0|Q6_K|Q6_K_L)
      echo "Near-Lossless|${CYAN}"
      return 0
      ;;
  esac
  
  # Recommended / Balanced (best quality/size tradeoff)
  # Where most people land. Q4_K_M is the llama.cpp default recommendation.
  # Q5_1 is legacy llama.cpp format, still solid.
  case "$quant" in
    Q5_K_M|Q5_K_S|Q5_1|Q4_K_M)
      echo "Recommended|${YELLOW}"
      return 0
      ;;
  esac
  
  # Fast / Compressed (noticeable but acceptable loss)
  # Starts to be perceptible on precise tasks, but usable for daily work.
  # IQ4 formats use importance matrix for better quality than K-quant equivalents.
  # Q4_1 is legacy llama.cpp format.
  case "$quant" in
    Q4_K_S|Q4_1|Q4_0|IQ4_XS|IQ4_NL)
      echo "Fast|${YELLOW}"
      return 0
      ;;
  esac
  
  # Lossy / Aggressive (significant quality loss)
  # Reserved for very limited machines. Quality takes a serious hit, especially on small models (< 7B).
  # Q3_K_M and Q3_K_S have minimal difference, both degrade noticeably.
  case "$quant" in
    Q3_K_L|Q3_K_M|Q3_K_S|Q2_K|Q2_K_L|IQ3_XXS|IQ3_XS|IQ2_XXS|IQ2_XS)
      echo "Lossy|${RED}"
      return 0
      ;;
  esac
  
  # Experimental
  # Very recent or extreme formats. MXFP4 is Microsoft's format for specific NPU/GPU.
  # IQ1_S is 1-bit quantization, mainly for research.
  case "$quant" in
    MXFP4|IQ1_S)
      echo "Experimental|${MAGENTA}"
      return 0
      ;;
  esac
  
  # Unknown/Other
  echo "Other|${DIM}"
}

# ===========================================================================
# END PHASE 3
# ===========================================================================

# ---------------------------------------------------------------------------
# main — entry point
# ---------------------------------------------------------------------------
main() {
  # Parse arguments
  local query=""
  local action="interactive"
  
  while [[ $# -gt 0 ]]; do
    case "$1" in
      -h|--help)
        usage
        ;;
      --version)
        echo "llama-models v${VERSION}"
        exit 0
        ;;
      --mode)
        MODE="$2"
        shift 2
        ;;
      --install-deps)
        install_dependencies
        exit 0
        ;;
      search)
        action="search"
        query="$2"
        shift 2
        ;;
      list)
        action="list"
        shift
        ;;
      *)
        query="$1"
        action="search"
        shift
        ;;
    esac
  done
  
  # Detect mode if not forced
  if [[ -z "$MODE" ]]; then
    detect_mode "$action"
  fi
  
  # Only show mode info for interactive/search commands
  if [[ "$action" != "list" ]]; then
    info "Running in ${BOLD}${MODE}${RESET} mode"
  fi
  
  # Create models directory
  mkdir -p "$MODELS_DIR"
  
  # Execute action based on mode
  case "$action" in
    interactive)
      if [[ "$MODE" == "premium" ]]; then
        run_premium_interactive
      else
        run_minimal_interactive
      fi
      ;;
    search)
      if [[ "$MODE" == "premium" ]]; then
        run_premium_search "$query"
      else
        run_minimal_search "$query"
      fi
      ;;
    list)
      list_local_models
      ;;
  esac
}

# ---------------------------------------------------------------------------
# Placeholder functions (to be implemented in next phases)
# ---------------------------------------------------------------------------
# run_premium_interactive — interactive mode with gum TUI
# ---------------------------------------------------------------------------
run_premium_interactive() {
  echo
  gum style \
    --border rounded \
    --border-foreground 212 \
    --padding "1 2" \
    --margin "1 0" \
    "llama-models — Premium Mode" \
    "Powered by gum TUI"
  
  # Prompt for search query with gum input
  local query
  query=$(gum input --placeholder "Enter search query (or leave empty for popular models)...")
  
  run_premium_search "$query"
}

# ---------------------------------------------------------------------------
# run_premium_search — search with gum-based fuzzy finder
# Args: $1 = search query
# ---------------------------------------------------------------------------
run_premium_search() {
  local query="$1"
  local limit=50
  
  # Search models via HuggingFace API
  local results
  results=$(search_models "$query" "$limit" 0)
  
  if [[ -z "$results" ]] || [[ "$results" == "[]" ]]; then
    gum style --foreground 208 "No GGUF models found for query: ${query}"
    return 1
  fi
  
  # Parse results into arrays
  local -a model_jsons
  local -a model_display_lines
  local -a model_ids
  
  info "Parsing results..."
  
  mapfile -t model_jsons < <(echo "$results" | jq -c '.[]')
  
  # Build display lines for gum filter
  for i in "${!model_jsons[@]}"; do
    local metadata
    metadata=$(parse_model_metadata "${model_jsons[i]}")
    
    local model_id downloads size quant_count
    IFS='|' read -r model_id downloads size quant_count <<< "$metadata"
    
    model_ids[i]="$model_id"
    
    # Format display line: "ID | downloads | variants"
    printf -v display_line "%-50s  %10s downloads  %3s variants" \
      "$model_id" "$downloads" "$quant_count"
    model_display_lines[i]="$display_line"
  done
  
  echo
  gum style --foreground 212 "Found ${#model_ids[@]} GGUF models"
  echo
  
  # Use gum filter for fuzzy selection
  local selected_line
  selected_line=$(printf "%s\n" "${model_display_lines[@]}" | \
    gum filter \
      --placeholder "Search models..." \
      --prompt "❯ " \
      --height 20 \
      --indicator "→")
  
  if [[ -z "$selected_line" ]]; then
    info "No model selected"
    return 0
  fi
  
  # Find which model was selected
  local selected_index=-1
  for i in "${!model_display_lines[@]}"; do
    if [[ "${model_display_lines[i]}" == "$selected_line" ]]; then
      selected_index=$i
      break
    fi
  done
  
  if [[ $selected_index -ge 0 ]]; then
    show_premium_model_quantizations "${model_jsons[selected_index]}" "${model_ids[selected_index]}"
  fi
}

# ---------------------------------------------------------------------------
# show_premium_model_quantizations — TUI for selecting quantization
# Args: $1 = model JSON object
#       $2 = model_id (for display)
# ---------------------------------------------------------------------------
show_premium_model_quantizations() {
  local model_json="$1"
  local model_id="$2"
  
  echo
  gum style \
    --border rounded \
    --border-foreground 86 \
    --padding "0 2" \
    --margin "1 0" \
    "Model: $model_id"
  
  # Get list of GGUF files
  local gguf_files
  gguf_files=$(list_gguf_files "$model_json")
  
  if [[ -z "$gguf_files" ]] || [[ "$gguf_files" == "[]" ]]; then
    warn "No GGUF files found in model"
    return 1
  fi
  
  # Parse GGUF files into arrays
  local -a filenames
  local -a sizes
  local -a quants
  local -a display_lines
  
  mapfile -t < <(echo "$gguf_files" | jq -r '.[] | "\(.filename)|\(.size)|\(.quant)"')
  
  for line in "${MAPFILE[@]}"; do
    IFS='|' read -r filename size quant <<< "$line"
    
    filenames+=("$filename")
    sizes+=("$size")
    quants+=("$quant")
    
    # Format size
    local size_str
    if [[ "$size" =~ ^[0-9]+$ ]] && [[ "$size" -gt 0 ]]; then
      size_str=$(format_size "$size")
    else
      size_str="N/A"
    fi
    
    # Get quality label
    local label_info label_text label_color
    label_info=$(get_quant_label "$quant")
    IFS='|' read -r label_text label_color <<< "$label_info"
    
    # Format display line for gum choose (with color-coded label)
    printf -v display_line "%-12s  %8s  ${label_color}%-10s${RESET}  %s" \
      "$quant" "$size_str" "$label_text" "$filename"
    display_lines+=("$display_line")
  done
  
  # Show quantizations in a formatted table
  echo
  gum style --foreground 212 "Available Quantizations (${#filenames[@]} variants):"
  echo
  
  # Create table header
  echo -e "${BOLD}Quantization  Size      Quality     Filename${RESET}"
  echo "─────────────────────────────────────────────────────────────────────────────"
  
  for display_line in "${display_lines[@]}"; do
    echo -e "$display_line"
  done
  
  echo
  
  # Use gum choose for selection
  local choices=("${quants[@]}" "Back" "Quit")
  local choice
  choice=$(printf "%s\n" "${choices[@]}" | gum choose)
  
  if [[ -z "$choice" ]] || [[ "$choice" == "Quit" ]]; then
    info "Exiting"
    exit 0
  elif [[ "$choice" == "Back" ]]; then
    # Go back to model selection
    run_premium_search "$query"
    return 0
  fi
  
  # Find selected quantization
  local selected_index=-1
  for i in "${!quants[@]}"; do
    if [[ "${quants[i]}" == "$choice" ]]; then
      selected_index=$i
      break
    fi
  done
  
  if [[ $selected_index -ge 0 ]]; then
    local filename="${filenames[selected_index]}"
    
    # Create model-specific directory
    local sanitized_id
    sanitized_id=$(echo "$model_id" | tr '/' '_')
    local dest_dir="${MODELS_DIR}/${sanitized_id}"
    
    # Download with aria2c if available, otherwise curl
    if check_dependency aria2c; then
      download_aria2c_file "$model_id" "$filename" "$dest_dir"
    else
      download_gguf_file "$model_id" "$filename" "$dest_dir"
    fi
    
    echo
    gum style --foreground 82 "✓ Model ready to use!"
    echo
    gum style --foreground 212 "Saved to: ${BOLD}${dest_dir}${RESET}"
  fi
}

# ---------------------------------------------------------------------------
# run_minimal_interactive — interactive mode with basic prompts
# ---------------------------------------------------------------------------
run_minimal_interactive() {
  echo
  echo -e "${BOLD}llama-models${RESET} — Interactive Model Browser"
  echo
  
  # Prompt for search query
  read -p "Enter search query (or press Enter for popular models): " query
  
  run_minimal_search "$query"
}

# ---------------------------------------------------------------------------
# run_minimal_search — search and select models with bash select menu
# Args: $1 = search query
# ---------------------------------------------------------------------------
run_minimal_search() {
  local query="$1"
  local limit=20
  local offset=0
  local has_more=true
  
  # Initialize arrays to accumulate results across pages
  local -a all_model_ids=()
  local -a all_model_metadata=()
  local -a all_model_jsons=()
  
  # Main pagination loop
  while true; do
    # Search models via HuggingFace API with offset for pagination
    local results
    results=$(search_models "$query" "$limit" "$offset")
    
    if [[ -z "$results" ]] || [[ "$results" == "[]" ]]; then
      if [[ $offset -eq 0 ]]; then
        # No results on first page
        echo
        warn "No GGUF models found for query: ${query}"
        echo
        echo "Try a different search term, or browse popular models with:"
        echo "  llama-models search"
        exit 0
      else
        # No more results on subsequent pages
        has_more=false
        break
      fi
    fi
    
    # Parse results into arrays
    local -a model_jsons
    
    echo
    info "Parsing results..."
    
    # Use mapfile to avoid process substitution issues
    mapfile -t model_jsons < <(echo "$results" | jq -c '.[]')
    
    # Check if we got fewer results than requested (means this is the last page)
    if [[ ${#model_jsons[@]} -lt $limit ]]; then
      has_more=false
    fi
    
    # Process each model and append to accumulated arrays
    for i in "${!model_jsons[@]}"; do
      local metadata
      metadata=$(parse_model_metadata "${model_jsons[i]}")
      
      # Extract just the model ID for display
      local model_id
      model_id=$(echo "$metadata" | cut -d'|' -f1)
      
      all_model_ids+=("$model_id")
      all_model_metadata+=("$metadata")
      all_model_jsons+=("${model_jsons[i]}")
    done
    
    # Display all accumulated results in a formatted table
    echo
    echo -e "${BOLD}Found ${#all_model_ids[@]} GGUF models:${RESET}"
    echo
    echo -e "${BOLD}#   Model ID                                Downloads   Variants${RESET}"
    echo "─────────────────────────────────────────────────────────────────────────────"
    
    for i in "${!all_model_ids[@]}"; do
      local metadata="${all_model_metadata[i]}"
      local model_id downloads size quant_count
      
      IFS='|' read -r model_id downloads size quant_count <<< "$metadata"
      
      # Truncate model_id if too long
      local display_id="$model_id"
      if [[ ${#model_id} -gt 38 ]]; then
        display_id="${model_id:0:35}..."
      fi
      
      printf "${CYAN}%-3d${RESET} %-38s %10s   ${BOLD}%8s${RESET}\n" \
        "$((i+1))" "$display_id" "$downloads" "$quant_count"
    done
    
    echo
    
    # Build select menu options
    local -a select_options=("${all_model_ids[@]}")
    
    # Add pagination/quit options
    if [[ "$has_more" == "true" ]]; then
      select_options+=("── Show more ──")
    fi
    select_options+=("Quit")
    
    # Bash select menu for model selection
    echo -e "${BOLD}Select a model to download:${RESET}"
    
    PS3="Enter number: "
    local choice
    select choice in "${select_options[@]}"; do
      if [[ -n "$choice" ]]; then
        if [[ "$choice" == "Quit" ]]; then
          echo
          info "Exiting."
          exit 0
        elif [[ "$choice" == "── Show more ──" ]]; then
          # Load next page
          offset=$((offset + limit))
          echo
          info "Loading more results..."
          break
        else
          # User selected a model
          # Find the selected model's index
          local selected_index=-1
          for i in "${!all_model_ids[@]}"; do
            if [[ "${all_model_ids[i]}" == "$choice" ]]; then
              selected_index=$i
              break
            fi
          done
          
          if [[ $selected_index -ge 0 ]]; then
            show_model_quantizations "${all_model_jsons[selected_index]}" "$choice"
            return 0
          fi
        fi
      else
        echo "Invalid selection. Try again or press Ctrl+C to exit."
      fi
    done
    
    # If we broke out of select to load more, continue the while loop
    if [[ "$choice" == "── Show more ──" ]]; then
      continue
    else
      # If we selected a model, we returned above, so this should not happen
      break
    fi
  done
}

# ---------------------------------------------------------------------------
# show_model_quantizations — display available quants and let user pick one
# Args: $1 = model JSON object
#       $2 = model_id (for display)
# ---------------------------------------------------------------------------
show_model_quantizations() {
  local model_json="$1"
  local model_id="$2"
  
  echo
  echo -e "${BOLD}Model:${RESET} ${model_id}"
  echo
  
  # Get list of GGUF files
  local gguf_files
  gguf_files=$(list_gguf_files "$model_json")
  
  if [[ -z "$gguf_files" ]] || [[ "$gguf_files" == "[]" ]]; then
    warn "No GGUF files found in this model"
    exit 1
  fi
  
  # Parse into arrays
  local -a filenames
  local -a sizes
  local -a quants
  
  # Use mapfile to avoid process substitution deadlock
  local -a gguf_array
  mapfile -t gguf_array < <(echo "$gguf_files" | jq -c '.[]')
  
  for i in "${!gguf_array[@]}"; do
    local filename size quant
    filename=$(echo "${gguf_array[i]}" | jq -r '.filename')
    size=$(echo "${gguf_array[i]}" | jq -r '.size')
    quant=$(echo "${gguf_array[i]}" | jq -r '.quant')
    
    filenames[i]="$filename"
    sizes[i]="$size"
    quants[i]="$quant"
  done
  
  # Display quantization options
  echo -e "${BOLD}Available quantizations:${RESET}"
  echo
  echo -e "${BOLD}#   Quant     Size        Quality     Filename${RESET}"
  echo "─────────────────────────────────────────────────────────────────────────────"
  
  for i in "${!filenames[@]}"; do
    local size_human
    size_human=$(format_size "${sizes[i]}")
    
    # Get quality label
    local label_info label_text label_color
    label_info=$(get_quant_label "${quants[i]}")
    IFS='|' read -r label_text label_color <<< "$label_info"
    
    # Truncate filename if too long
    local display_name="${filenames[i]}"
    if [[ ${#display_name} -gt 35 ]]; then
      display_name="${display_name:0:32}..."
    fi
    
    printf "${CYAN}%-3d${RESET} %-9s %-11s ${label_color}%-10s${RESET} %s\n" \
      "$((i+1))" "${quants[i]}" "$size_human" "$label_text" "$display_name"
  done
  
  echo
  
  # Select menu for quantization
  echo -e "${BOLD}Select a quantization to download (or 'q' to quit):${RESET}"
  
  PS3="Enter number: "
  local choice
  select choice in "${quants[@]}" "Back" "Quit"; do
    if [[ -n "$choice" ]]; then
      if [[ "$choice" == "Quit" ]]; then
        echo
        info "Exiting."
        exit 0
      elif [[ "$choice" == "Back" ]]; then
        return 0
      fi
      
      # Find selected quant's index
      local selected_index=-1
      for i in "${!quants[@]}"; do
        if [[ "${quants[i]}" == "$choice" ]]; then
          selected_index=$i
          break
        fi
      done
      
      if [[ $selected_index -ge 0 ]]; then
        # Create organized storage path: models_dir/model_id/
        local safe_model_id
        safe_model_id=$(echo "$model_id" | tr '/' '_')
        local dest_dir="${MODELS_DIR}/${safe_model_id}"
        
        # Download the selected file
        download_gguf_file "$model_id" "${filenames[selected_index]}" "$dest_dir"
        
        echo
        success "Model ready to use!"
        echo
        echo -e "Saved to: ${BOLD}${dest_dir}${RESET}"
        echo
        echo "Run with llama.cpp:"
        echo "  llama-cli -m ${dest_dir}/${filenames[selected_index]}"
        echo
        
        exit 0
      fi
    else
      echo "Invalid selection. Try again or press Ctrl+C to exit."
    fi
  done
}

list_local_models() {
  info "Listing models in: $MODELS_DIR"
  
  if [[ ! -d "$MODELS_DIR" ]] || [[ -z "$(ls -A "$MODELS_DIR" 2>/dev/null)" ]]; then
    echo "No models downloaded yet."
    echo
    echo "Download models with: llama-models search <query>"
    exit 0
  fi
  
  echo
  echo -e "${BOLD}Downloaded Models${RESET}"
  echo
  echo -e "${BOLD}Model ID                                Quant      Size       Downloaded${RESET}"
  echo "─────────────────────────────────────────────────────────────────────────────"
  
  # Find all metadata.json files
  local found=0
  while IFS= read -r -d '' metadata_file; do
    if [[ -f "$metadata_file" ]]; then
      local model_id
      model_id=$(jq -r '.model_id // "unknown"' "$metadata_file")
      
      # Process each download in the metadata
      local downloads_count
      downloads_count=$(jq -r '.downloads | length' "$metadata_file")
      
      for ((i=0; i<downloads_count; i++)); do
        local filename quant size downloaded_at
        filename=$(jq -r ".downloads[$i].filename // \"unknown\"" "$metadata_file")
        quant=$(jq -r ".downloads[$i].quantization // \"unknown\"" "$metadata_file")
        size=$(jq -r ".downloads[$i].file_size // 0" "$metadata_file")
        downloaded_at=$(jq -r ".downloads[$i].downloaded_at // \"unknown\"" "$metadata_file")
        
        # Format size
        local size_human
        size_human=$(format_size "$size")
        
        # Format date (just date, no time)
        local date_short
        if [[ "$downloaded_at" =~ ^([0-9]{4}-[0-9]{2}-[0-9]{2}) ]]; then
          date_short="${BASH_REMATCH[1]}"
        else
          date_short="$downloaded_at"
        fi
        
        # Truncate model_id if too long
        local display_model_id="$model_id"
        if [[ ${#display_model_id} -gt 38 ]]; then
          display_model_id="${display_model_id:0:35}..."
        fi
        
        # Get quality label
        local label_info label_text label_color
        label_info=$(get_quant_label "$quant")
        IFS='|' read -r label_text label_color <<< "$label_info"
        
        printf "%-40s ${label_color}%-10s${RESET} %-10s %s\n" \
          "$display_model_id" "$quant" "$size_human" "$date_short"
        
        found=1
      done
    fi
  done < <(find "$MODELS_DIR" -type f -name "metadata.json" -print0)
  
  if [[ $found -eq 0 ]]; then
    echo "No models with metadata found."
    echo
    echo -e "${DIM}Note: Models downloaded before metadata tracking won't appear here.${RESET}"
    echo -e "${DIM}Re-download to generate metadata.${RESET}"
  fi
  
  echo
}

# ---------------------------------------------------------------------------
# Execute main if script is run directly (not sourced)
# ---------------------------------------------------------------------------
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
  main "$@"
fi
